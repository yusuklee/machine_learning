{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:34.200228200Z",
     "start_time": "2026-01-12T06:46:34.186985800Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2153a4f09fd07b23",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:37.895314100Z",
     "start_time": "2026-01-12T06:46:34.201229800Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.016882800Z",
     "start_time": "2026-01-12T06:46:37.956877400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "print(device)"
   ],
   "id": "2460a4812502bdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.051997800Z",
     "start_time": "2026-01-12T06:46:38.019880200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv1 = nn.Conv2d(1,1,3, padding=1) # in , out channel  필터크기 패딩순\n",
    "input1 = torch.Tensor(1,1,5,5) #배치 채널 행 열 이엇나\n",
    "out1 = conv1(input1)\n",
    "out1.shape"
   ],
   "id": "aa9898918c4504a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.081043800Z",
     "start_time": "2026-01-12T06:46:38.052996400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out2 = nn.MaxPool2d(2)(out1)\n",
    "out2.shape"
   ],
   "id": "ca90fe1555fdc9a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.112102100Z",
     "start_time": "2026-01-12T06:46:38.082049300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv1 = nn.Sequential(\n",
    "    nn.Conv2d(1,32,3,1,1), #입력채널 1 출력채널 32 라\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32), #여기서 32로 받고\n",
    "    nn.MaxPool2d(2)\n",
    ")\n",
    "input1 = torch.Tensor(1,1,28,28) # 1 32 14 14\n",
    "out1 = conv1(input1)\n",
    "out1.shape"
   ],
   "id": "712a89b4f100f116",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 14, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.161266Z",
     "start_time": "2026-01-12T06:46:38.113106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv1 = nn.Sequential(\n",
    "    nn.Conv2d(1,32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 128, 3, 1, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(2)\n",
    ")\n",
    "input1 = torch.Tensor(1,1,28,28)\n",
    "out1 = conv1(input1)\n",
    "flat_out1 = out1.view(out1.size(0),-1)\n",
    "print(out1.shape, flat_out1.shape)"
   ],
   "id": "9d43a221693576ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 3, 3]) torch.Size([1, 1152])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.171485500Z",
     "start_time": "2026-01-12T06:46:38.162272200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "           nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential (\n",
    "            nn.Linear(3 * 3 * 128, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm1d(128), # Linear Layer 이므로, BatchNorm1d() 사용해야 함\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm1d(64), # Linear Layer 이므로, BatchNorm1d() 사용해야 함\n",
    "            nn.Linear(64, 10),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "       x1 = self.conv_layers(x)\n",
    "       flat_x = x1.view(x1.size(0),-1)\n",
    "       return self.linear_layers(flat_x)\n",
    "\n"
   ],
   "id": "9d53c1ffff7779b2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.179782800Z",
     "start_time": "2026-01-12T06:46:38.172491800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ],
   "id": "2bad87f2b807d942",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.254332300Z",
     "start_time": "2026-01-12T06:46:38.179782800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_rawdata = datasets.MNIST(root = 'dataset',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = 'dataset',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "print('number of training data : ', len(train_rawdata))\n",
    "print('number of test data : ', len(test_dataset))"
   ],
   "id": "e709176beb56ccc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data :  60000\n",
      "number of test data :  10000\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.338057800Z",
     "start_time": "2026-01-12T06:46:38.258331900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_idx, val_idx, _, _ = train_test_split(\n",
    "    range(len(train_rawdata)),\n",
    "    train_rawdata.targets,\n",
    "    stratify=train_rawdata.targets,\n",
    "    test_size=0.2\n",
    ")\n"
   ],
   "id": "a65c25fe27051293",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.345045100Z",
     "start_time": "2026-01-12T06:46:38.339057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = Subset(train_rawdata, train_idx)\n",
    "val = Subset(train_rawdata, val_idx)"
   ],
   "id": "74dd0da514d42297",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.363048100Z",
     "start_time": "2026-01-12T06:46:38.346042600Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(train), len(val))",
   "id": "b4b5a14c603d2169",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.382956Z",
     "start_time": "2026-01-12T06:46:38.364048600Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset",
   "id": "63c650725165af7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: dataset\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.393469600Z",
     "start_time": "2026-01-12T06:46:38.384956300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "train_batches = DataLoader(train, 128, True)\n",
    "val_batches = DataLoader(val, 128, True)\n",
    "test_batches = DataLoader(test_dataset, 128, False)"
   ],
   "id": "79da257852489ba4",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.419521300Z",
     "start_time": "2026-01-12T06:46:38.393469600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNNModel()\n",
    "model"
   ],
   "id": "80d1bd24aba469e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): LeakyReLU(negative_slope=0.1)\n",
       "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.1)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (7): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.427681100Z",
     "start_time": "2026-01-12T06:46:38.421026800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "id": "51b9b844d5fb43b2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:38.438704800Z",
     "start_time": "2026-01-12T06:46:38.428686500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, early, iter_num, show_interval):\n",
    "    train_losses, valid_losses, lowes_loss = [], [], np.inf\n",
    "    lowest_index = 0\n",
    "    best_model = deepcopy(model.state_dict())\n",
    "    for i in range(iter_num):\n",
    "\n",
    "        loss_t, loss_v = 0,0\n",
    "\n",
    "        model.train()\n",
    "        for x, y in train_batches:\n",
    "            y_pred = model(x)\n",
    "            loss = loss_func(y_pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_t+=loss.item()\n",
    "        loss_t/=len(train_batches)\n",
    "        train_losses.append(loss_t)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_batches:\n",
    "                y_pred = model(x)\n",
    "                loss = loss_func(y_pred,y)\n",
    "                loss_v+=loss.item()\n",
    "\n",
    "            loss_v/=len(val_batches)\n",
    "            valid_losses.append(loss_v)\n",
    "\n",
    "            if valid_losses[-1] < lowes_loss:\n",
    "                lowes_loss = valid_losses[-1]\n",
    "                lowest_index = i\n",
    "                best_model = deepcopy(model.state_dict())\n",
    "            else:\n",
    "                if early > 0 and lowest_index+ early < i:\n",
    "                    print('early stopped')\n",
    "                    model.load_state_dict(best_model)\n",
    "                    break\n",
    "\n",
    "            if i % show_interval ==0:\n",
    "                print(train_losses[-1], valid_losses[-1])\n",
    "\n",
    "        model.load_state_dict(best_model)\n",
    "        return model,lowes_loss, train_losses, valid_losses"
   ],
   "id": "eaf77bb1bf094dc2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T06:46:46.000831800Z",
     "start_time": "2026-01-12T06:46:43.481403400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNNModel().to(device)\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "wrong_x, wrong_y, actual_y = [],[],[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y  in test_batches:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss +=loss_func(y_pred,y)\n",
    "        pred = torch.argmax(y_pred, dim=1)\n",
    "        correct+=pred.eq(y).sum().item()\n",
    "\n",
    "        wrong_idx = pred.ne(y).nonzero()[:,0].cpu().numpy().tolist()\n",
    "        for i in wrong_idx:\n",
    "            wrong_x.append(x[i].cpu())\n",
    "            wrong_y.append(pred[i].cpu())\n",
    "            actual_y.append(y[i].cpu())\n",
    "\n",
    "test_loss /= len(test_batches)\n",
    "print('Average Test Loss: {:.4f}'.format(test_loss))\n",
    "print('Accuracy: {}/{} ({:.2f}%)'.format(correct, len(test_batches.dataset), 100 * correct / len(test_batches.dataset)))"
   ],
   "id": "e4af6b61456d6d4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 2.3035\n",
      "Accuracy: 1010/10000 (10.10%)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "839164d77b2b399f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
