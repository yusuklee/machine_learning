{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:07:08.520831900Z",
     "start_time": "2026-01-10T02:07:08.499893100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "x= torch.rand(1, requires_grad=True)\n",
    "y = torch.rand(1)\n",
    "y.requires_grad = True\n",
    "loss = y-x"
   ],
   "id": "53a112669fa84d5a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:07:08.546036300Z",
     "start_time": "2026-01-10T02:07:08.522830900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss.backward()\n",
    "print(x.grad, y.grad)"
   ],
   "id": "f27510bbf52e10f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.]) tensor([1.])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:07:08.565654300Z",
     "start_time": "2026-01-10T02:07:08.547348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "W = torch.rand(4,3, requires_grad=True)\n",
    "b=torch.rand(3,requires_grad=True)\n",
    "z=torch.matmul(x,W)+b\n",
    "print(W,b,z)"
   ],
   "id": "eb9a62a86b00fc53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0569, 0.8867, 0.5724],\n",
      "        [0.6367, 0.4474, 0.7930],\n",
      "        [0.0605, 0.4417, 0.9671],\n",
      "        [0.5428, 0.0057, 0.2992]], requires_grad=True) tensor([0.7784, 0.0515, 0.8422], requires_grad=True) tensor([2.0753, 1.8331, 3.4739], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:07:08.587194600Z",
     "start_time": "2026-01-10T02:07:08.566953300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as f\n",
    "loss = f.mse_loss(z,y)\n",
    "loss.backward()\n",
    "print(W.grad, b.grad)"
   ],
   "id": "77ec3064e095d03d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3835, 1.2220, 2.3159],\n",
      "        [1.3835, 1.2220, 2.3159],\n",
      "        [1.3835, 1.2220, 2.3159],\n",
      "        [1.3835, 1.2220, 2.3159]]) tensor([1.3835, 1.2220, 2.3159])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:07:08.622197500Z",
     "start_time": "2026-01-10T02:07:08.588195900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "w = torch.tensor(4.0, requires_grad=True)\n",
    "z=2*w\n",
    "z.backward() #이러면 w.grad에  2가 저장이되나?\n",
    "print(w.grad) # w->A ->z 로 식이가면 w.grad에는 z의 w편미분이 들어간다"
   ],
   "id": "a5151aad800edf30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:07:08.717395300Z",
     "start_time": "2026-01-10T02:07:08.622197500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD([W,b], lr=lr)\n",
    "for i in range(300):\n",
    "    z= torch.matmul(x,W)+b\n",
    "    loss = F.mse_loss(z,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%100==0:\n",
    "        print(i,W,b,loss)"
   ],
   "id": "ae230e91e26e59c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[ 0.0431,  0.8745,  0.5493],\n",
      "        [ 0.6229,  0.4352,  0.7698],\n",
      "        [ 0.0466,  0.4295,  0.9439],\n",
      "        [ 0.5290, -0.0065,  0.2760]], requires_grad=True) tensor([0.7646, 0.0393, 0.8191], requires_grad=True) tensor(6.5783, grad_fn=<MseLossBackward0>)\n",
      "100 tensor([[-0.3446,  0.5321, -0.0997],\n",
      "        [ 0.2352,  0.0928,  0.1208],\n",
      "        [-0.3411,  0.0870,  0.2950],\n",
      "        [ 0.1413, -0.3490, -0.3730]], requires_grad=True) tensor([ 0.3769, -0.3032,  0.1701], requires_grad=True) tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "200 tensor([[-0.3577,  0.5205, -0.1216],\n",
      "        [ 0.2221,  0.0812,  0.0989],\n",
      "        [-0.3541,  0.0755,  0.2731],\n",
      "        [ 0.1282, -0.3605, -0.3949]], requires_grad=True) tensor([ 0.3638, -0.3147,  0.1482], requires_grad=True) tensor(8.4879e-06, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:08:53.088786700Z",
     "start_time": "2026-01-10T02:08:53.079135400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression(4,3)"
   ],
   "id": "f90346bfa19ac1ac",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:09:46.871307400Z",
     "start_time": "2026-01-10T02:09:46.631376900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.ones(4)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  #w랑 b가 모델 파라미터에잇음\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    pred = model(x)\n",
    "    loss = F.mse_loss(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "id": "d9aa0989f2f4f252",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:11:06.877066800Z",
     "start_time": "2026-01-10T02:11:06.849955300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print (param)"
   ],
   "id": "804f9cd7878388c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3130e-13, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1290, -0.1585, -0.0169, -0.0455],\n",
      "        [-0.1461,  0.0824, -0.1381,  0.1239],\n",
      "        [ 0.0386,  0.1285, -0.1844,  0.3003]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0918,  0.0779, -0.2830], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:10:57.440906400Z",
     "start_time": "2026-01-10T02:10:57.386306400Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.parameters())",
   "id": "ba37b4507fc64601",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000022E46063E60>\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ab9464e6896cc96d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
