{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-13T06:15:25.768882500Z",
     "start_time": "2026-01-13T06:15:25.753858500Z"
    }
   },
   "source": [
    "from xml.sax.handler import feature_external_ges\n",
    "\n",
    "from kaggle_project2.practice import progress_interval, lowest_loss, valid_losses\n",
    "from networkx.algorithms.bipartite.basic import color\n",
    "\n",
    "sequence_length = 28 # MNIST row 를 일종의 순서(sequence) 로 다룸\n",
    "feature_size = 28 # 입력 차원\n",
    "hidden_size = 128 # Hidden Layer 사이즈 설정처럼 설정\n",
    "num_layers = 4 # stacked RNN (최대 4개까지는 Gradient Vanishing 현상이 적을 수 있으므로)\n",
    "dropout_p = 0.2 # dropout rate\n",
    "output_size = 10 # 0 ~ 9 숫자 부류(클래스)\n",
    "minibatch_size = 128 # minibatch_size"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:15:29.329197600Z",
     "start_time": "2026-01-13T06:15:25.769883900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ],
   "id": "db0ec6478fa01715",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:15:29.345279600Z",
     "start_time": "2026-01-13T06:15:29.336526400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_size, num_layers, dropout_p, output_size, model_type):\n",
    "        super().__init__()\n",
    "        if model_type == 'rnn':\n",
    "            self.go = nn.RNN( #nn.RNN은 모든 시점의 출력과 마지막 시점의 히든 레이어를\n",
    "                input_size=feature_size,\n",
    "                hidden_size = hidden_size,\n",
    "                num_layers = num_layers,\n",
    "                batch_first=True,\n",
    "                dropout = dropout_p,\n",
    "                bidirectional=True\n",
    "            )\n",
    "        elif model_type == 'lstm':\n",
    "            self.go = nn.LSTM(\n",
    "                input_size = feature_size,\n",
    "                hidden_size = hidden_size,\n",
    "                num_layers = num_layers,\n",
    "                batch_first = True,\n",
    "                dropout = dropout_p,\n",
    "                bidirectional = True\n",
    "            )\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size*2),\n",
    "            nn.Linear(hidden_size*2, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        out, _ = self.go(x)\n",
    "        out = out[:, -1]\n",
    "        y = self.layers(out)\n",
    "        return y"
   ],
   "id": "2216548a3f7892b4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:15:29.372065700Z",
     "start_time": "2026-01-13T06:15:29.346279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "data1 = torch.full((minibatch_size, sequence_length, 2* hidden_size),1)\n",
    "data2 = data1[:,-1] #마지막시간의 데이터들임\n",
    "print(data1.shape, data2.shape)"
   ],
   "id": "3a8342b3c4223c8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 28, 256]) torch.Size([128, 256])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:15:30.898722100Z",
     "start_time": "2026-01-13T06:15:30.866265300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data3 = torch.full((minibatch_size,1,sequence_length,feature_size),1)\n",
    "data4 = data3.reshape(-1,sequence_length,feature_size)\n",
    "print(data3.shape, data4.shape)\n"
   ],
   "id": "afdf2320de2e087d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28]) torch.Size([128, 28, 28])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:16:01.593758400Z",
     "start_time": "2026-01-13T06:16:01.554071700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Net(feature_size, hidden_size, num_layers, dropout_p, output_size, 'rnn')\n",
    "model"
   ],
   "id": "a68ab7ea349f90e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (go): RNN(28, 128, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (layers): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (3): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:17:47.123337200Z",
     "start_time": "2026-01-13T06:17:36.393906400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_rawdata = datasets.MNIST(root='dataset',\n",
    "                               train = True,\n",
    "                               download=True,\n",
    "                               transform = transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='dataset',\n",
    "                              train=False,\n",
    "                              download=True,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "print('number of training data : ', len(train_rawdata))\n",
    "print('number of test data : ', len(test_dataset))"
   ],
   "id": "5987793ea7df813c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data :  60000\n",
      "number of test data :  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:18:04.703246600Z",
     "start_time": "2026-01-13T06:18:04.622047700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VALIDATION_RATE = 0.2\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(train_rawdata)), # X index 번호\n",
    "    train_rawdata.targets, # y\n",
    "    stratify=train_rawdata.targets, # 균등분포\n",
    "    test_size=VALIDATION_RATE # test dataset 비율\n",
    ")"
   ],
   "id": "59318cd5c3f99eff",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:18:22.143145400Z",
     "start_time": "2026-01-13T06:18:22.124116600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = Subset(train_rawdata, train_indices)\n",
    "validation_dataset = Subset(train_rawdata, val_indices)"
   ],
   "id": "a89eb6e24d104a67",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:18:37.583888300Z",
     "start_time": "2026-01-13T06:18:37.541178300Z"
    }
   },
   "cell_type": "code",
   "source": "print (len(train_dataset), len(validation_dataset), len(test_dataset))",
   "id": "d8e33e85a1fa1709",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000 10000\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:19:09.821357800Z",
     "start_time": "2026-01-13T06:19:09.808003900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "minibatch_size = 128 # Mini-batch 사이즈는 128 로 설정\n",
    "# create batches\n",
    "train_batches = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "val_batches = DataLoader(validation_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_batches = DataLoader(test_dataset, batch_size=minibatch_size, shuffle=True)"
   ],
   "id": "7c42c7691c1c02aa",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:19:14.098765500Z",
     "start_time": "2026-01-13T06:19:14.076100700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_func = nn.NLLLoss() # log softmax 는 NLLLoss() 로 진행해야 함\n",
    "optimizer = torch.optim.Adam(model.parameters()) # Adam, learning rate 필요없음"
   ],
   "id": "76cab3187a99af08",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:25:45.334521700Z",
     "start_time": "2026-01-13T06:25:45.313014600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, early_stop, n_epochs, progress_interval):\n",
    "\n",
    "    train_losses, valid_losses, lowest_loss = [],[],np.inf\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for x,y in train_batches:\n",
    "            x = x.reshape(-1,sequence_length, feature_size)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_func(y_pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_batches:\n",
    "                x = x.reshape(-1,sequence_length, feature_size)\n",
    "                y_pred = model(x)\n",
    "                loss = loss_func(y_pred, y)\n",
    "                valid_losses.append(loss.item())\n",
    "\n",
    "        if valid_losses[-1]<lowest_loss:\n",
    "            lowest_loss = valid_losses[-1]\n",
    "            lowest_epoch = epoch\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            if early_stop >0 and lowest_epoch+early_stop <epoch:\n",
    "                print('early stopped', epoch, 'epochs')\n",
    "                model.load_state_dict(best_model)\n",
    "                break\n",
    "\n",
    "            if (epoch % progress_interval)==0:\n",
    "                print(train_losses[-1], valid_losses[-1], lowest_loss, lowest_epoch, epoch)\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, lowest_loss, train_losses, valid_losses"
   ],
   "id": "bc85ad339d158ef9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:57:00.212213900Z",
     "start_time": "2026-01-13T06:26:32.795027200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nb_epochs = 100\n",
    "progress_interval = 3\n",
    "early_stop = 30\n",
    "\n",
    "model, lowest_loss, train_losses, valid_losses = train_model(model, early_stop, nb_epochs, progress_interval)"
   ],
   "id": "66a86f3c236b8ee9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13185760378837585 0.23740315437316895 0.13335460424423218 3 6\n",
      "0.16851583123207092 0.19397228956222534 0.028506798669695854 8 9\n",
      "0.10461896657943726 0.08502926677465439 0.028506798669695854 8 12\n",
      "0.15423429012298584 0.25985845923423767 0.028506798669695854 8 15\n",
      "0.1602725088596344 0.18484580516815186 0.026772739365696907 18 21\n",
      "0.023635968565940857 0.17230403423309326 0.026772739365696907 18 24\n",
      "0.1337500363588333 0.2515651285648346 0.026772739365696907 18 27\n",
      "0.08454056084156036 0.19280236959457397 0.026772739365696907 18 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m progress_interval = \u001B[32m3\u001B[39m\n\u001B[32m      3\u001B[39m early_stop = \u001B[32m30\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m model, lowest_loss, train_losses, valid_losses = \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnb_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress_interval\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, early_stop, n_epochs, progress_interval)\u001B[39m\n\u001B[32m     10\u001B[39m loss = loss_func(y_pred, y)\n\u001B[32m     12\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m optimizer.step()\n\u001B[32m     15\u001B[39m train_losses.append(loss.item())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\yusuk1\\Lib\\site-packages\\torch\\_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\yusuk1\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\yusuk1\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "model.eval()\n",
    "\n",
    "wrong_samples, wrong_pred, actual_preds = list(), list(), list()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x,y in test_batches:\n",
    "        y_test_pred = model(x)\n",
    "        loss =loss_func(y_test_pred, y)\n",
    "        test_loss+=loss_func(y_test_pred,y)\n",
    "        pred = torch.argmax(y_test_pred,dim=1)\n",
    "        correct +=pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "        wrong_idx = (pred !=y.view_as(pred)).nonzero()[:, 0]\n",
    "        for i in wrong_idx:\n",
    "            wrong_samples.append(x[i])\n",
    "            wrong_pred.append(pred[i])\n",
    "            actual_preds.append(y.view_as(pred)[i])\n",
    "\n",
    "test_loss/=len(test_batches.dataset )\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy : {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_batches.dataset),100.*correct/len(test_batches.dataset)))"
   ],
   "id": "d0e861383962db3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(18,20))\n",
    "\n",
    "for index in range(len(wrong_samples)):\n",
    "    plt.subplot(10,10,index+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wrong_samples[index].numpy().reshape(28,28), cmap='gray')\n",
    "    plt.title('pred'+ str(wrong_pred[index].item())+ \"(\"+str(actual_preds[index].item())+\")\", color='red')"
   ],
   "id": "8f8c1528038a9dba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53a1b30b7d53aeed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
